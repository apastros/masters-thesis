{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Absolute Fundamentals\n",
    "\n",
    "Relevent code should be in the directory above this one, for future reference. This journal will not necessarily go into detail about the code as I have created a (hopefully) sufficient number comments to make the code legible.\n",
    "\n",
    "---\n",
    "The first step is learning the basics about python data analysis. For this purpose, there are a few python resources that come in incredibly handy. Along with those are a plethora of online documentation to understand how to use packages (and vanilla python) effectively. Most importantly is practice, which can be done on many open source, or otherwise publicly available, data sets.\n",
    "\n",
    "---\n",
    "\n",
    "## Online Resources\n",
    "\n",
    "---\n",
    "\n",
    "### [Kaggle](https://www.kaggle.com/)\n",
    "Many data sources and some basic tutorials. Hosted by google and has a number of competitions going on at any given time. The famous [*Titanic Data Set*](https://www.kaggle.com/c/titanic) is often used as the introduction to data analysis and visualization. \n",
    "\n",
    "### Jake VanderPlas's [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)\n",
    "Dr. VanderPlas is an astrophysicist who has worked on a lot of data science packages, programs, and tutorials. As of writing this, he is a google dev and a main contributor of a number of machine learning python packages. This book (and a couple others) are available for free and are incredibly useful. \n",
    "\n",
    "**There are many other online resources for a number of different things. This is a very documented field. Below is a list of useful learning materials**\n",
    "\n",
    "### Important Libraries and their Documentation\n",
    "\n",
    "- [Anaconda](https://www.anaconda.com/): An invaluable set of IDEs including Spyder, Jupyter, and over 100 commonly used packages.\n",
    "\n",
    "- [Numpy](https://numpy.org/): Very important math package for python that includes quick built in operations and data structures. Helpful for quickly performing copious calculations. Basically lets python work at the speed of c and not the speed of python. \n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/): Data visualization, manipulation, import and export. Very useful for data exploration.\n",
    "\n",
    "- [Sklearn](https://scikit-learn.org/stable/): This is a massive package that contains all manner of machine learning and AI algorithms built in. This makes implementing different algorithms as easy as changing a single line of code.\n",
    "\n",
    "- [Matplotlib](https://matplotlib.org/): De facto graphing software.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources\n",
    "This thesis will be utilizing and comparing different machine learning techniques on astronomical datasets. The following are important data sources that may or may not be fully explored in the future. Note: Many of these are easily accessible by CasJobs, which is an online SQL server. \n",
    "- [SDSS](https://www.sdss.org/)\n",
    "- [Gaia](https://gea.esac.esa.int/archive/)\n",
    "- [Galaxy Zoo](https://www.zooniverse.org/projects/zookeeper/galaxy-zoo/)\n",
    "- [Tess](https://archive.stsci.edu/tess/)\n",
    "- [Simbad](http://simbad.u-strasbg.fr/simbad/)\n",
    "- [Panstarr](https://panstarrs.stsci.edu/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating SDSS Data\n",
    "\n",
    "This is the line of analysis that I did as I learned more about ML techniques, better coding practices, and useful data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the data\n",
    "Classifying SDSS rows as Star, Galaxy, or QSO. The true answers were given in the data. This was for practice and familiarity with using the algorithms.\n",
    "\n",
    "Using CasJobs was not too difficult but I did hit some snags. Firstly, I attempted to download the entirety of the SDSS Data Release 16 directly. This ended up being hundreds of gigabytes as it contained image data along with hundreds of columns of information. Evidently, only certain columns of information were necessary and trying to download and import a lot of useless data only to select a few columns was entirely wasteful. **Lesson: Only get the data you need**\n",
    "\n",
    "The first classifier I used was the Random Forest Classifier. This, in conjunction with my choice of features to analyze, led to an accuracy of 96.6% after 12 minutes of run time. The features I used here were wavemin, wavemax, wCoverage, ra, dec, and z. Upon reflection, the only feature that had a justifiable influence was z. After this, I began to use features relating to the colour magnitudes of the object. **Lesson: Use features that make sense**\n",
    "\n",
    "There were also errors in the data that had to be cleaned before it could be useful. The data was then scaled as to improve the performance of the support vector classifier and for uniformity between algorithms. **Lesson: Investigate your data, clean if needed. It will probably be needed.**\n",
    "\n",
    "After finding a good set of features, it was time to use them on the models and determine accuracies. Initial estimations used only one test of each algorithm. This produced an accuracy that could differ depending on random state and the choice for the test and train data. So, a stratified k folds cross test is used to determine a more accurate value for estimating the accuracy of each model. \"Stratified\" in this sense means that each fold of the test has the same proportion of Stars, Galaxies, and QSOs as the original data. This should decrease bias and produce results more uniformly. As each algorithm can take as long as over an hour to complete, this should be complete within a few days of execution. **Lesson: Test your model thoroghly. Your accuracy needs to be justifiable, testable, and meaningful.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
